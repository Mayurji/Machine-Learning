{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "**Dimensionality Reduction is used for a well known problem called as 'Curse Of Dimensionality'.**\n",
    "**The Wikipedia defines of Curse of Dimensionality as follows : The curse of dimensionality refers to various phenomena that arise when analyzing and organizing data in high-dimensional spaces (often with hundreds or thousands of dimensions) that do not occur in low-dimensional settings such as the three-dimensional physical space of everyday experience. **\n",
    "\n",
    "** To overcome the above problem, we do dimensionality reduction. SO how to perform Dimensionality Reduction, there are number of ways of Dimensionality reduction such as feature selection and Feature Extraction.**\n",
    "\n",
    "** We will be looking at Feature Extraction methods of Dimensionality Reduction **\n",
    "\n",
    "** Two we'll known dimension reduction technique are PCA and Truncated SVD **\n",
    "\n",
    "   **PCA** : Principal Components Analysis means components which are able to explain the maximum amount of variance of the features with respect to target variable, if we include all feature as components then we get the variance of 1.\n",
    "     \n",
    "   **TruncatedSVD**: It is very similar to PCA, the only difference one can specify technically is PCA performs variance calculation on Covariance matrix but TSVD does the same on sample direct vectors.\n",
    "     \n",
    "   **Our ultimate aim here is to explain the maximum variance of the feature using as less components as possible.**\n",
    "     \n",
    "**Please find the below link for better understanding of PCA vs Truncated SVD:**\n",
    "     \n",
    "**\"https://stats.stackexchange.com/questions/239481/difference-between-scikit-learn-implementations-of-pca-and-truncatedsvd\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as m\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import skimage as img\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are loading the digits dataset for our problem. We can notice that we have around 64 feature representing the digit.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_digits.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAFJCAYAAADngYQlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f5647b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.array(load_digits.data[10]).reshape(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = load_digits.data\n",
    "y = load_digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Variance of an feature with respect to target variable, explains a lot about the relationship between feature and target variable **\n",
    "\n",
    "** We have a list of components included in our list over which we try to explain the variance. As the components are increases the variance increases. What is right number of components ? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance with  4  Components:  0.431379300562\n",
      "Accuracy Score with Random Forest Classifier 0.788888888889\n",
      "Accuracy Score with Gaussian NB  0.708888888889\n",
      "--------------------------------------------------\n",
      "Explained Variance with  8  Components:  0.662835691107\n",
      "Accuracy Score with Random Forest Classifier 0.931111111111\n",
      "Accuracy Score with Gaussian NB  0.866666666667\n",
      "--------------------------------------------------\n",
      "Explained Variance with  12  Components:  0.779908849429\n",
      "Accuracy Score with Random Forest Classifier 0.948888888889\n",
      "Accuracy Score with Gaussian NB  0.942222222222\n",
      "--------------------------------------------------\n",
      "Explained Variance with  16  Components:  0.847958128738\n",
      "Accuracy Score with Random Forest Classifier 0.962222222222\n",
      "Accuracy Score with Gaussian NB  0.946666666667\n",
      "--------------------------------------------------\n",
      "Explained Variance with  20  Components:  0.894062078056\n",
      "Accuracy Score with Random Forest Classifier 0.951111111111\n",
      "Accuracy Score with Gaussian NB  0.944444444444\n",
      "--------------------------------------------------\n",
      "Explained Variance with  24  Components:  0.925961028517\n",
      "Accuracy Score with Random Forest Classifier 0.913333333333\n",
      "Accuracy Score with Gaussian NB  0.94\n",
      "--------------------------------------------------\n",
      "Explained Variance with  28  Components:  0.949848051575\n",
      "Accuracy Score with Random Forest Classifier 0.926666666667\n",
      "Accuracy Score with Gaussian NB  0.931111111111\n",
      "--------------------------------------------------\n",
      "Explained Variance with  32  Components:  0.96632162913\n",
      "Accuracy Score with Random Forest Classifier 0.948888888889\n",
      "Accuracy Score with Gaussian NB  0.942222222222\n",
      "--------------------------------------------------\n",
      "Explained Variance with  63  Components:  1.0\n",
      "Accuracy Score with Random Forest Classifier 0.891111111111\n",
      "Accuracy Score with Gaussian NB  0.895555555556\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for x in list([4,8,12,16,20,24,28,32,63]):\n",
    "    dimReduction = TruncatedSVD(n_components=x)\n",
    "    X_DR = dimReduction.fit_transform(X)\n",
    "    print(\"Explained Variance with \", x ,\" Components: \" ,dimReduction.explained_variance_ratio_.sum())\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_DR,y,test_size=0.25)\n",
    "    RFC = RandomForestClassifier()\n",
    "    mnb = GaussianNB()\n",
    "    RFC.fit(X_train,y_train)\n",
    "    mnb.fit(X_train,y_train)\n",
    "    y_pred = RFC.predict(X_test)\n",
    "    y_prediction = mnb.predict(X_test)\n",
    "    print(\"Accuracy Score with Random Forest Classifier\",m.accuracy_score(y_test,y_pred))\n",
    "    print(\"Accuracy Score with Gaussian NB \",m.accuracy_score(y_test,y_prediction))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance with 4  Components:  0.487139380086\n",
      "Accuracy Score with Random Forest Classifier 0.817777777778\n",
      "Accuracy Score with Gaussian NB 0.755555555556\n",
      "--------------------------------------------------\n",
      "Explained Variance with 8  Components:  0.673904519232\n",
      "Accuracy Score with Random Forest Classifier 0.926666666667\n",
      "Accuracy Score with Gaussian NB 0.882222222222\n",
      "--------------------------------------------------\n",
      "Explained Variance with 12  Components:  0.784673995424\n",
      "Accuracy Score with Random Forest Classifier 0.922222222222\n",
      "Accuracy Score with Gaussian NB 0.902222222222\n",
      "--------------------------------------------------\n",
      "Explained Variance with 16  Components:  0.849398516022\n",
      "Accuracy Score with Random Forest Classifier 0.94\n",
      "Accuracy Score with Gaussian NB 0.917777777778\n",
      "--------------------------------------------------\n",
      "Explained Variance with 20  Components:  0.894295070641\n",
      "Accuracy Score with Random Forest Classifier 0.942222222222\n",
      "Accuracy Score with Gaussian NB 0.924444444444\n",
      "--------------------------------------------------\n",
      "Explained Variance with 24  Components:  0.926071927865\n",
      "Accuracy Score with Random Forest Classifier 0.948888888889\n",
      "Accuracy Score with Gaussian NB 0.942222222222\n",
      "--------------------------------------------------\n",
      "Explained Variance with 28  Components:  0.949881680946\n",
      "Accuracy Score with Random Forest Classifier 0.928888888889\n",
      "Accuracy Score with Gaussian NB 0.955555555556\n",
      "--------------------------------------------------\n",
      "Explained Variance with 32  Components:  0.966350417405\n",
      "Accuracy Score with Random Forest Classifier 0.922222222222\n",
      "Accuracy Score with Gaussian NB 0.942222222222\n",
      "--------------------------------------------------\n",
      "Explained Variance with 63  Components:  1.0\n",
      "Accuracy Score with Random Forest Classifier 0.9\n",
      "Accuracy Score with Gaussian NB 0.902222222222\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for x in list([4,8,12,16,20,24,28,32,63]):\n",
    "    dimReduction = PCA(n_components=x)\n",
    "    X_DR_PCA = dimReduction.fit_transform(X)\n",
    "    print(\"Explained Variance with\", x ,\" Components: \" ,dimReduction.explained_variance_ratio_.sum())\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_DR_PCA,y,test_size=0.25)\n",
    "    RFC_2 = RandomForestClassifier()\n",
    "    RFC_2.fit(X_train,y_train)\n",
    "    mnb.fit(X_train,y_train)\n",
    "    y_pred = RFC_2.predict(X_test)\n",
    "    y_prediction = mnb.predict(X_test)\n",
    "    print(\"Accuracy Score with Random Forest Classifier\",m.accuracy_score(y_test,y_pred))\n",
    "    print(\"Accuracy Score with Gaussian NB\",m.accuracy_score(y_test,y_prediction))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** From 64 Feature vector to 24 Feature, to get the same result :**\n",
    "We can see from the changes in variance with respect to the components, the changes saturate after n_components is 24 which can seen from the result mentioned below !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_1_Comp = PCA(n_components=24)\n",
    "X_1 = pca_1_Comp.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260694418377089"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_1_Comp.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_1,y,test_size = 0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "y_predict = gnb.predict(X_test)\n",
    "print(m.accuracy_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
