{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Analysis on Bank Marketing Dataset\n",
    "\n",
    "** Bank Marketing Dataset contains both type variables 'Categorical' and 'Numerical'.\n",
    "\n",
    "** Categorical Variable:\n",
    "\n",
    "    * Marital - (Married , Single , Divorced)\n",
    "    * Job - (Management,Blue-Collar,Technician,entrepreneur,retired,admin.,services,selfemployed,housemaid,student,unemployed,unknown)\n",
    "    * Contact - (Telephone,Cellular,Unknown)\n",
    "    * Education - (Primary,Secondary,Tertiary,Unknown)\n",
    "    * Month - (Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec)\n",
    "    * Poutcome - (Success,Failure,Other,Unknown)\n",
    "    * Housing - (Yes/No)\n",
    "    * Loan - (Yes/No)\n",
    "    * is_success - (Yes/No)\n",
    "    * Default - (Yes/No)\n",
    "    \n",
    "** Numerical Variable:\n",
    "\n",
    "    * Age\n",
    "    * Balance\n",
    "    * Day\n",
    "    * Duration\n",
    "    * Campaign\n",
    "    * Pdays\n",
    "    * Previous\n",
    "    \n",
    "    \n",
    "    ** Mean, Standard Deviation, Min, Max, Quantile output of all numerical variable:\n",
    "    \n",
    "        \n",
    "        |Desc   |age     |balance  |duration|campaign|pdays    |previous|day      |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |count  |45211.00|45211.00 |45211.00|45211.00|45211.00 |45211.00|45211.00 |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |mean   |40.93   |1362.27  |258.16  |2.76    |40.19    |0.58    |15.80    |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |std    |10.61   |3044.76  |257.52  |3.09    |100.12   |2.30    |8.32     |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |min    |18.00   |-8019.00 |0.00    |1.00    |-1.00    |0.00    |1.00     | \n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |25%    |33.00   |72.00    |103.00  |1.00    |-1.00    |0.00    |8.00     |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |50%    |39.00   |448.00   |180.00  |2.00    |-1.00    |0.00    |16.00    |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |75%    |48.00   |1428.00  |319.00  |3.00    |-1.00    |0.00    |21.00    |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |max    |95.00   |102127.00|4918.00 |63.00   |871.00   |275.00  |31.00    |\n",
    "         \n",
    "         \n",
    "  ** Understanding above table :\n",
    "  \n",
    "  ** Outlier : \" data_point > (Q3 * 1.5) \" is said to be outlier\n",
    "  \n",
    "  #### Age: \n",
    "          \n",
    "   ** Average age of the people in the dataset is ~41 with std of 10.61\n",
    "   \n",
    "   ** Min. age is 18\n",
    "   \n",
    "   ** Max. age is 95\n",
    "   \n",
    "   ** quantile 75%(percentile) refers that 75 percentage of the people have 48 or less age !\n",
    "   \n",
    "   ** As 95 is max, there is great chance that its a outlier \"48*(3/2) = 72\". So anything greater than 72 is outlier.\n",
    "          \n",
    "  #### Balance: \n",
    "          \n",
    "   ** Average balance of the people in the dataset is (approx)1326.27 with std of 3044.76, as standard deviation is quite huge it means that balance is wide spread across the dataset.\n",
    "   \n",
    "   ** Min. balance is -8019\n",
    "   \n",
    "   ** Max. balance is 102127\n",
    "   \n",
    "   ** quantile 75%(percentile) refers that 75 percentage of the people have 1428 or less balance.\n",
    "   \n",
    "   ** while comparing with 75% quantile, 102127 is very huge and its a outlier data point.\n",
    "          \n",
    "  #### Duration: \n",
    "          \n",
    "   ** Average duration of the people speaking in the dataset is (approx)258.16 with std of 257.52, as standard deviation is quite huge it means that duration is wide spread across the dataset.\n",
    "   \n",
    "   ** Min. duration is 0\n",
    "   \n",
    "   ** Max. duration is 4918\n",
    "   \n",
    "   ** quantile 75%(percentile) refers that 75 percentage of the people spoke for 319 seconds or less.\n",
    "   \n",
    "   ** while comparing with 75% quantile, 4918 is a outlier data point.\n",
    "\n",
    "  #### Pdays: \n",
    "          \n",
    "   ** Average no. of days passed after the client was contacted from previous campaign in the dataset is (approx)40.19 with std of 100.12.\n",
    "   \n",
    "   ** Min. pdays is -1\n",
    "   \n",
    "   ** Max. pdays is 871\n",
    "   \n",
    "   ** quantile 75%(percentile),for 75% of records it is -1 days, which means the Client was not contacted. \n",
    "          \n",
    "  #### Campaign: \n",
    "          \n",
    "   ** Average no. of contacts performed during the current campaign for a client in the dataset is (approx)2.76 with std of 3.09.\n",
    "   \n",
    "   ** Min. balance is 1\n",
    "   \n",
    "   ** Max. balance is 63\n",
    "   \n",
    "   ** quantile 75%(percentile),for 75% of records, 3 times the client has been contacted in the current campaign for a client.\n",
    "   \n",
    "   ** while comparing with 75% quantile,63 is a outlier data point.\n",
    "          \n",
    "  #### Previous:\n",
    "      \n",
    "   ** Average no. of contacts performed before this campaign for a client in the dataset is (approx)0.58 with std of 2.30.\n",
    "   \n",
    "   ** Min. balance is 0\n",
    "   \n",
    "   ** Max. balance is 275\n",
    "   \n",
    "   ** quantile 75%(percentile),for 75% of records, 0 times the client has been contacted before this campaign.\n",
    "   \n",
    "   ** while comparing with 75% quantile,275 is a outlier data point.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as m\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "data = pd.read_csv('D:/textAnalysis/marketing-data.csv',sep=',',header='infer')\n",
    "data = data.drop(['day'],axis=1)\n",
    "\n",
    "def binaryType_(data):\n",
    "    \n",
    "    data.is_success.replace(('yes', 'no'), (1, 0), inplace=True)\n",
    "    data.default.replace(('yes','no'),(1,0),inplace=True)\n",
    "    data.housing.replace(('yes','no'),(1,0),inplace=True)\n",
    "    data.loan.replace(('yes','no'),(1,0),inplace=True)\n",
    "    data.marital.replace(('married','single','divorced'),(1,2,3),inplace=True)\n",
    "    data.contact.replace(('telephone','cellular','unknown'),(1,2,3),inplace=True)\n",
    "    data.month.replace(('jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'),(1,2,3,4,5,6,7,8,9,10,11,12),inplace=True)\n",
    "    data.education.replace(('primary','secondary','tertiary','unknown'),(1,2,3,4),inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = binaryType_(data)\n",
    "\n",
    "# for k in range(len(data.contact.unique())):\n",
    "#     data[\"contact_\"+str(data.contact.unique()[k])] = (data.contact == data.contact.unique()[k]).astype(int)\n",
    "\n",
    "# for l in range(len(data.education.unique())):\n",
    "#     data['education_'+str(data.education.unique()[l])] = (data.education == data.education.unique()[l]).astype(int)\n",
    "\n",
    "# for n in range(len(data.month.unique())):\n",
    "#     data['month_'+str(data.month.unique()[n])] = (data.month == data.month.unique()[n]).astype(int)\n",
    "\n",
    "\n",
    "#print(data.day.describe())\n",
    "#print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = data.drop(['education'],axis=1)\n",
    "#data = data.drop(['marital'],axis=1)\n",
    "#data = data.drop(['contact'],axis=1)\n",
    "data = data.drop(['poutcome'],axis=1)\n",
    "#data = data.drop(['month'],axis=1)\n",
    "#data = data.drop(['job'],axis=1)\n",
    "data['duration'] = data['duration']/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'month', 'duration', 'campaign', 'pdays', 'previous',\n",
      "       'is_success', 'pdays_not_contacted', 'pdays_passed', 'Not Contacted',\n",
      "       'Contacted', 'Neg. Balance', 'No Balance', 'Pos. Balance'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def age_(data):\n",
    "    \n",
    "    data['Adult']\n",
    "    data.loc[(data['age'] <= 30) & (data['age'] >= 18),'Adult'] = 1\n",
    "    data.loc[(data['age'] <= 45) & (data['age'] >= 31),'Middle Age'] = 2\n",
    "    data.loc[(data['age'] <= 60) & (data['age'] >= 46),'Elder'] = 3\n",
    "    data.loc[data['age'] >=61,'old'] = 4\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = age_(data)\n",
    "\n",
    "def campaign_(data):\n",
    "    \n",
    "    data.loc[data['campaign'] == 1,'campaign'] = 1\n",
    "    data.loc[(data['campaign'] >= 2) & (data['campaign'] <= 3),'campaign'] = 2\n",
    "    data.loc[data['campaign'] >= 4,'campaign'] = 3\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = campaign_(data)\n",
    "#print(data.campaign.value_counts())\n",
    "def duration_(data):\n",
    "    \n",
    "    data.loc[data['duration'] < 1,'duration'] = 0\n",
    "    data.loc[(data['duration'] >= 1) & (data['duration'] <= 3),'duration'] = 1\n",
    "    data.loc[(data['duration'] > 3) & (data['duration'] <= 5),'duration'] = 2\n",
    "    data.loc[(data['duration'] > 5) & (data['duration'] <= 8),'duration'] = 3\n",
    "    data.loc[data['duration'] > 8,'duration'] = 4\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = duration_(data)\n",
    "\n",
    "def pdays_(data):\n",
    "    data['pdays_not_contacted'] = 0\n",
    "    data['pdays_passed'] = 0\n",
    "    data.loc[data['pdays'] == -1 ,'pdays_not_contacted'] = 1\n",
    "    data.loc[(data['pdays'] >= 1) & (data['pdays'] <=50) ,'pdays_passed'] = 1\n",
    "    data.loc[(data['pdays'] >= 51) & (data['pdays'] <=100) ,'pdays_passed'] = 2\n",
    "    data.loc[data['pdays'] >= 101,'pdays_passed'] = 3\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = pdays_(data)\n",
    "\n",
    "def previous_(data):\n",
    "    \n",
    "    data['Not Contacted'] = 0\n",
    "    data['Contacted'] = 0\n",
    "    data.loc[data['previous'] == 0 ,'Not Contacted'] = 1\n",
    "    data.loc[(data['previous'] >= 1) & (data['pdays'] <=50) ,'Contacted'] = 1\n",
    "    data.loc[(data['previous'] >= 51) & (data['pdays'] <=100) ,'Contacted'] = 2\n",
    "    data.loc[data['previous'] >= 101,'Contacted'] = 3\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = previous_(data)\n",
    "\n",
    "def balance_(data):\n",
    "    data['Neg. Balance'] = 0\n",
    "    data['No Balance'] = 0\n",
    "    data['Pos. Balance'] = 0\n",
    "    \n",
    "    data.loc[~data['balance']<0,'Neg. Balance'] = 1\n",
    "    data.loc[data['balance'] == 0,'No Balance'] = 1\n",
    "    data.loc[(data['balance'] >= 1) & (data['balance'] <= 100),'Pos. Balance'] = 1\n",
    "    data.loc[(data['balance'] >= 101) & (data['balance'] <= 500),'Pos. Balance'] = 2\n",
    "    data.loc[(data['balance'] >= 501) & (data['balance'] <= 2000),'Pos. Balance'] = 3\n",
    "    data.loc[(data['balance'] >= 2001) & (data['balance'] <= 10000),'Pos. Balance'] = 4\n",
    "    data.loc[data['balance'] >= 10001,'Pos. Balance'] = 5\n",
    "    \n",
    "    return data\n",
    "\n",
    "def job_(data):\n",
    "    \n",
    "    data.loc[data['job'] == \"management\",'job'] = 1\n",
    "    data.loc[data['job'] == \"technician\",'job'] = 2\n",
    "    data.loc[data['job'] == \"entrepreneur\",'job'] = 3\n",
    "    data.loc[data['job'] == \"blue-collar\",'job'] = 4\n",
    "    data.loc[data['job'] == \"retired\",'job'] = 5\n",
    "    data.loc[data['job'] == \"admin.\",'job'] = 6\n",
    "    data.loc[data['job'] == \"services\",'job'] = 7\n",
    "    data.loc[data['job'] == \"self-employed\",'job'] = 8\n",
    "    data.loc[data['job'] == \"unemployed\",'job'] = 9\n",
    "    data.loc[data['job'] == \"student\",'job'] = 10\n",
    "    data.loc[data['job'] == \"housemaid\",'job'] = 11\n",
    "    data.loc[data['job'] == \"unknown\",'job'] = 12\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = balance_(data)\n",
    "data = job_(data)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  is_success\n",
      "0    1    0.162873\n",
      "1    2    0.098808\n",
      "2    3    0.097813\n",
      "3    4    0.422559\n",
      "    job  is_success\n",
      "0     1    0.137556\n",
      "1     2    0.110570\n",
      "2     3    0.082717\n",
      "3     4    0.072750\n",
      "4     5    0.227915\n",
      "5     6    0.122027\n",
      "6     7    0.088830\n",
      "7     8    0.118429\n",
      "8     9    0.155027\n",
      "9    10    0.286780\n",
      "10   11    0.087903\n",
      "11   12    0.118056\n",
      "   duration  is_success\n",
      "0       0.0    0.001932\n",
      "1       1.0    0.038887\n",
      "2       2.0    0.109176\n",
      "3       3.0    0.167613\n",
      "4       4.0    0.410835\n",
      "     pdays  is_success\n",
      "0       -1    0.091573\n",
      "1        1    0.400000\n",
      "2        2    0.054054\n",
      "3        3    0.000000\n",
      "4        4    0.500000\n",
      "5        5    0.000000\n",
      "6        6    0.100000\n",
      "7        7    0.000000\n",
      "8        8    0.000000\n",
      "9        9    0.250000\n",
      "10      10    0.666667\n",
      "11      12    0.000000\n",
      "12      13    0.500000\n",
      "13      14    0.111111\n",
      "14      15    0.000000\n",
      "15      17    0.250000\n",
      "16      18    0.000000\n",
      "17      19    0.000000\n",
      "18      20    0.500000\n",
      "19      21    0.250000\n",
      "20      22    0.333333\n",
      "21      24    0.000000\n",
      "22      25    0.000000\n",
      "23      26    0.000000\n",
      "24      27    0.250000\n",
      "25      28    0.111111\n",
      "26      29    0.333333\n",
      "27      30    0.000000\n",
      "28      31    0.200000\n",
      "29      32    0.000000\n",
      "..     ...         ...\n",
      "529    717    0.000000\n",
      "530    728    1.000000\n",
      "531    745    0.000000\n",
      "532    749    1.000000\n",
      "533    756    0.000000\n",
      "534    760    0.000000\n",
      "535    761    1.000000\n",
      "536    769    1.000000\n",
      "537    771    0.000000\n",
      "538    772    0.000000\n",
      "539    774    0.000000\n",
      "540    775    0.000000\n",
      "541    776    1.000000\n",
      "542    778    0.000000\n",
      "543    779    0.000000\n",
      "544    782    1.000000\n",
      "545    784    1.000000\n",
      "546    791    0.000000\n",
      "547    792    0.500000\n",
      "548    804    1.000000\n",
      "549    805    1.000000\n",
      "550    808    0.000000\n",
      "551    826    0.000000\n",
      "552    828    1.000000\n",
      "553    831    0.000000\n",
      "554    838    0.000000\n",
      "555    842    1.000000\n",
      "556    850    0.000000\n",
      "557    854    1.000000\n",
      "558    871    0.000000\n",
      "\n",
      "[559 rows x 2 columns]\n",
      "   campaign  is_success\n",
      "0         1    0.145976\n",
      "1         2    0.112005\n",
      "2         3    0.073540\n",
      "   Neg. Balance  is_success\n",
      "0             0    0.055762\n",
      "1             1    0.122548\n",
      "   Pos. Balance  is_success\n",
      "0             0    0.068956\n",
      "1             1    0.080077\n",
      "2             2    0.112958\n",
      "3             3    0.130165\n",
      "4             4    0.166058\n",
      "5             5    0.162847\n",
      "   No Balance  is_success\n",
      "0           0    0.119841\n",
      "1           1    0.083096\n"
     ]
    }
   ],
   "source": [
    "print (data[['age', 'is_success']].groupby(['age'], as_index=False).mean())\n",
    "print (data[['job', 'is_success']].groupby(['job'], as_index=False).mean())\n",
    "print (data[['duration', 'is_success']].groupby(['duration'], as_index=False).mean())\n",
    "print (data[['pdays', 'is_success']].groupby(['pdays'], as_index=False).mean())\n",
    "print (data[['campaign', 'is_success']].groupby(['campaign'], as_index=False).mean())\n",
    "print (data[['Neg. Balance', 'is_success']].groupby(['Neg. Balance'], as_index=False).mean())\n",
    "print (data[['Pos. Balance', 'is_success']].groupby(['Pos. Balance'], as_index=False).mean())\n",
    "print (data[['No Balance', 'is_success']].groupby(['No Balance'], as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Classifier  Accuracy\n",
      "0  Gradient Boosting Classifier  0.898408\n",
      "0  Gradient Boosting Classifier  0.893394\n",
      "0  Gradient Boosting Classifier  0.894942\n",
      "0  Adaptive Boosting Classifier  0.887349\n",
      "0  Adaptive Boosting Classifier  0.888750\n",
      "0  Adaptive Boosting Classifier  0.888750\n",
      "0  Linear Discriminant Analysis  0.883958\n",
      "0  Linear Discriminant Analysis  0.889855\n",
      "0  Linear Discriminant Analysis  0.885358\n"
     ]
    }
   ],
   "source": [
    "classifiers = {'Gradient Boosting Classifier':GradientBoostingClassifier(),'Adaptive Boosting Classifier':AdaBoostClassifier(),'Linear Discriminant Analysis':LinearDiscriminantAnalysis()}#,'Logistic Regression':LogisticRegression(),'Random Forest Classifier': RandomForestClassifier(),'K Nearest Neighbour':KNeighborsClassifier(8)}#'Decision Tree Classifier':DecisionTreeClassifier(),'Gaussian Naive Bayes Classifier':GaussianNB(),'Support Vector Classifier':SVC(probability=True),}\n",
    "\n",
    "data_y = pd.DataFrame(data['is_success'])\n",
    "#print(data_y.head())\n",
    "data_X = data.drop(['is_success','balance','previous','pdays'],axis=1)\n",
    "#print(data_X.head())\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "metrics_cols = ['Precision Score','Recall Score','F1-Score']\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "metric = pd.DataFrame(columns=metrics_cols)\n",
    "\n",
    "\n",
    "\n",
    "rs = StratifiedShuffleSplit(n_splits=3, test_size=0.3)\n",
    "rs.get_n_splits(data_X,data_y)\n",
    "\n",
    "for Name,classify in classifiers.items():\n",
    "    for train_index, test_index in rs.split(data_X,data_y):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X,X_test = data_X.iloc[train_index], data_X.iloc[test_index]\n",
    "        y,y_test = data_y.iloc[train_index], data_y.iloc[test_index]\n",
    "        cls = classify\n",
    "        cls =cls.fit(X,y)\n",
    "        y_out = cls.predict(X_test)\n",
    "        accuracy = m.accuracy_score(y_test,y_out)\n",
    "        precision = m.precision_score(y_test,y_out,average='macro')\n",
    "        recall = m.recall_score(y_test,y_out,average='macro')\n",
    "        f1_score = m.f1_score(y_test,y_out,average='macro')\n",
    "        log_entry = pd.DataFrame([[Name,accuracy]], columns=log_cols)\n",
    "        metric_entry = pd.DataFrame([[precision,recall,f1_score]], columns=metrics_cols)\n",
    "        log = log.append(log_entry)\n",
    "        metric = metric.append(metric_entry)\n",
    "        \n",
    "        \n",
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    39922\n",
      "1     5289\n",
      "Name: is_success, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.is_success.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Classifier  Accuracy\n",
      "0  Gradient Boosting Classifier  0.897597\n",
      "0  Gradient Boosting Classifier  0.895827\n",
      "0  Gradient Boosting Classifier  0.894721\n",
      "0  Adaptive Boosting Classifier  0.891109\n",
      "0  Adaptive Boosting Classifier  0.891330\n",
      "0  Adaptive Boosting Classifier  0.886980\n",
      "0  Linear Discriminant Analysis  0.884179\n",
      "0  Linear Discriminant Analysis  0.884842\n",
      "0  Linear Discriminant Analysis  0.882041\n"
     ]
    }
   ],
   "source": [
    "classifiers = {'Gradient Boosting Classifier':GradientBoostingClassifier(),'Adaptive Boosting Classifier':AdaBoostClassifier(),'Linear Discriminant Analysis':LinearDiscriminantAnalysis()}#,'Logistic Regression':LogisticRegression(),'Random Forest Classifier': RandomForestClassifier(),'K Nearest Neighbour':KNeighborsClassifier(8)}#'Decision Tree Classifier':DecisionTreeClassifier(),'Gaussian Naive Bayes Classifier':GaussianNB(),'Support Vector Classifier':SVC(probability=True),}\n",
    "\n",
    "data_y = pd.DataFrame(data['is_success'])\n",
    "#print(data_y.head())\n",
    "data_X = data.drop('is_success',axis=1)\n",
    "#print(data_X.head())\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "metrics_cols = ['Precision Score','Recall Score','F1-Score']\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "metric = pd.DataFrame(columns=metrics_cols)\n",
    "\n",
    "\n",
    "\n",
    "rs = ShuffleSplit(n_splits=3, test_size=0.3)\n",
    "rs.get_n_splits(data_X,data_y)\n",
    "\n",
    "for Name,classify in classifiers.items():\n",
    "    for train_index, test_index in rs.split(data_X,data_y):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X,X_test = data_X.iloc[train_index], data_X.iloc[test_index]\n",
    "        y,y_test = data_y.iloc[train_index], data_y.iloc[test_index]\n",
    "        cls = classify\n",
    "        cls =cls.fit(X,y)\n",
    "        y_out = cls.predict(X_test)\n",
    "        accuracy = m.accuracy_score(y_test,y_out)\n",
    "        precision = m.precision_score(y_test,y_out,average='macro')\n",
    "        recall = m.recall_score(y_test,y_out,average='macro')\n",
    "        f1_score = m.f1_score(y_test,y_out,average='macro')\n",
    "        log_entry = pd.DataFrame([[Name,accuracy]], columns=log_cols)\n",
    "        metric_entry = pd.DataFrame([[precision,recall,f1_score]], columns=metrics_cols)\n",
    "        log = log.append(log_entry)\n",
    "        metric = metric.append(metric_entry)\n",
    "        \n",
    "        \n",
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Precision Score  Recall Score  F1-Score\n",
      "0         0.758876      0.625467  0.660533\n",
      "0         0.773911      0.624490  0.661023\n",
      "0         0.769214      0.627422  0.663460\n",
      "0         0.737172      0.635290  0.666313\n",
      "0         0.739955      0.633501  0.665127\n",
      "0         0.714494      0.625950  0.653404\n",
      "0         0.725896      0.623013  0.652280\n",
      "0         0.722237      0.619149  0.648023\n",
      "0         0.696330      0.606426  0.631540\n"
     ]
    }
   ],
   "source": [
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Classifier  Accuracy\n",
      "0  Gradient Boosting Classifier  0.897597\n",
      "0  Gradient Boosting Classifier  0.895827\n",
      "0  Gradient Boosting Classifier  0.894721\n",
      "0  Adaptive Boosting Classifier  0.891109\n",
      "0  Adaptive Boosting Classifier  0.891330\n",
      "0  Adaptive Boosting Classifier  0.886980\n",
      "0  Linear Discriminant Analysis  0.884179\n",
      "0  Linear Discriminant Analysis  0.884842\n",
      "0  Linear Discriminant Analysis  0.882041\n",
      "0  Gradient Boosting Classifier  0.894132\n",
      "0  Adaptive Boosting Classifier  0.886833\n",
      "0  Linear Discriminant Analysis  0.884916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(data_X,data_y,test_size=0.3)\n",
    "for Name,classify in classifiers.items():\n",
    "#     for train_index, test_index in rs.split(data_X,data_y):\n",
    "#         #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#         X,X_test = data_X.iloc[train_index], data_X.iloc[test_index]\n",
    "#         y,y_test = data_y.iloc[train_index], data_y.iloc[test_index]\n",
    "    cls = classify\n",
    "    cls =cls.fit(X_train,y_train)\n",
    "    y_out = cls.predict(X_test)\n",
    "    accuracy = m.accuracy_score(y_test,y_out)\n",
    "    precision = m.precision_score(y_test,y_out,average='macro')\n",
    "    recall = m.recall_score(y_test,y_out,average='macro')\n",
    "    f1_score = m.f1_score(y_test,y_out,average='macro')\n",
    "    log_entry = pd.DataFrame([[Name,accuracy]], columns=log_cols)\n",
    "    metric_entry = pd.DataFrame([[precision,recall,f1_score]], columns=metrics_cols)\n",
    "    log = log.append(log_entry)\n",
    "    metric = metric.append(metric_entry)\n",
    "\n",
    "        \n",
    "print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFJCAYAAACsBZWNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc4ec9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data['age'],data['is_success'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3    13045\n",
      " 2    11190\n",
      " 4     7672\n",
      " 1     5195\n",
      "-1     3766\n",
      " 0     3514\n",
      " 5      829\n",
      "Name: balance, dtype: int64\n",
      "4     9732\n",
      "1     9458\n",
      "2     7597\n",
      "6     5171\n",
      "7     4154\n",
      "5     2264\n",
      "8     1579\n",
      "3     1487\n",
      "9     1303\n",
      "11    1240\n",
      "10     938\n",
      "12     288\n",
      "Name: job, dtype: int64\n",
      "1.0    18001\n",
      "2.0    10277\n",
      "3.0     6515\n",
      "4.0     5759\n",
      "0.0     4659\n",
      "Name: duration, dtype: int64\n",
      "-1    36954\n",
      " 3     6820\n",
      " 2     1179\n",
      " 1      258\n",
      "Name: pdays, dtype: int64\n",
      "2    18026\n",
      "1    17544\n",
      "3     9641\n",
      "Name: campaign, dtype: int64\n",
      "2    23733\n",
      "3    13260\n",
      "1     7030\n",
      "4     1188\n",
      "Name: age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.balance.value_counts())\n",
    "print(data.job.value_counts())\n",
    "print(data.duration.value_counts())\n",
    "print(data.pdays.value_counts())\n",
    "print(data.campaign.value_counts())\n",
    "print(data.age.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
