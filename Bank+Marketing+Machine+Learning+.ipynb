{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Analysis on Bank Marketing Dataset\n",
    "\n",
    "** Bank Marketing Dataset contains both type variables 'Categorical' and 'Numerical'.\n",
    "\n",
    "** Categorical Variable:\n",
    "\n",
    "    * Marital - (Married , Single , Divorced)\n",
    "    * Job - (Management,Blue-Collar,Technician,entrepreneur,retired,admin.,services,selfemployed,housemaid,student,unemployed,unknown)\n",
    "    * Contact - (Telephone,Cellular,Unknown)\n",
    "    * Education - (Primary,Secondary,Tertiary,Unknown)\n",
    "    * Month - (Jan,Feb,Mar,Apr,May,Jun,Jul,Aug,Sep,Oct,Nov,Dec)\n",
    "    * Poutcome - (Success,Failure,Other,Unknown)\n",
    "    * Housing - (Yes/No)\n",
    "    * Loan - (Yes/No)\n",
    "    * is_success - (Yes/No)\n",
    "    * Default - (Yes/No)\n",
    "    \n",
    "** Numerical Variable:\n",
    "\n",
    "    * Age\n",
    "    * Balance\n",
    "    * Day\n",
    "    * Duration\n",
    "    * Campaign\n",
    "    * Pdays\n",
    "    * Previous\n",
    "    \n",
    "    \n",
    "    ** Mean, Standard Deviation, Min, Max, Quantile output of all numerical variable:\n",
    "    \n",
    "        \n",
    "        |Desc   |age     |balance  |duration|campaign|pdays    |previous|day      |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |count  |45211.00|45211.00 |45211.00|45211.00|45211.00 |45211.00|45211.00 |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |mean   |40.93   |1362.27  |258.16  |2.76    |40.19    |0.58    |15.80    |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |std    |10.61   |3044.76  |257.52  |3.09    |100.12   |2.30    |8.32     |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |min    |18.00   |-8019.00 |0.00    |1.00    |-1.00    |0.00    |1.00     | \n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |25%    |33.00   |72.00    |103.00  |1.00    |-1.00    |0.00    |8.00     |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |50%    |39.00   |448.00   |180.00  |2.00    |-1.00    |0.00    |16.00    |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |75%    |48.00   |1428.00  |319.00  |3.00    |-1.00    |0.00    |21.00    |\n",
    "        |-------|--------|---------|--------|--------|---------|--------|---------|\n",
    "        |max    |95.00   |102127.00|4918.00 |63.00   |871.00   |275.00  |31.00    |\n",
    "         \n",
    "         \n",
    "  ** Understanding above table :\n",
    "  \n",
    "  ** Outlier : \" data_point > (Q3 * 1.5) \" is said to be outlier\n",
    "  \n",
    "  #### Age: \n",
    "          \n",
    "   ** Average age of the people in the dataset is ~41 with std of 10.61\n",
    "   \n",
    "   ** Min. age is 18\n",
    "   \n",
    "   ** Max. age is 95\n",
    "   \n",
    "   ** quantile 75%(percentile) refers that 75 percentage of the people have 48 or less age !\n",
    "   \n",
    "   ** As 95 is max, there is great chance that its a outlier \"48*(3/2) = 72\". So anything greater than 72 is outlier.\n",
    "          \n",
    "  #### Balance: \n",
    "          \n",
    "   ** Average balance of the people in the dataset is (approx)1326.27 with std of 3044.76, as standard deviation is quite huge it means that balance is wide spread across the dataset.\n",
    "   \n",
    "   ** Min. balance is -8019\n",
    "   \n",
    "   ** Max. balance is 102127\n",
    "   \n",
    "   ** quantile 75%(percentile) refers that 75 percentage of the people have 1428 or less balance.\n",
    "   \n",
    "   ** while comparing with 75% quantile, 102127 is very huge and its a outlier data point.\n",
    "          \n",
    "  #### Duration: \n",
    "          \n",
    "   ** Average duration of the people speaking in the dataset is (approx)258.16 with std of 257.52, as standard deviation is quite huge it means that duration is wide spread across the dataset.\n",
    "   \n",
    "   ** Min. duration is 0\n",
    "   \n",
    "   ** Max. duration is 4918\n",
    "   \n",
    "   ** quantile 75%(percentile) refers that 75 percentage of the people spoke for 319 seconds or less.\n",
    "   \n",
    "   ** while comparing with 75% quantile, 4918 is a outlier data point.\n",
    "\n",
    "  #### Pdays: \n",
    "          \n",
    "   ** Average no. of days passed after the client was contacted from previous campaign in the dataset is (approx)40.19 with std of 100.12.\n",
    "   \n",
    "   ** Min. pdays is -1\n",
    "   \n",
    "   ** Max. pdays is 871\n",
    "   \n",
    "   ** quantile 75%(percentile),for 75% of records it is -1 days, which means the Client was not contacted. \n",
    "          \n",
    "  #### Campaign: \n",
    "          \n",
    "   ** Average no. of contacts performed during the current campaign for a client in the dataset is (approx)2.76 with std of 3.09.\n",
    "   \n",
    "   ** Min. balance is 1\n",
    "   \n",
    "   ** Max. balance is 63\n",
    "   \n",
    "   ** quantile 75%(percentile),for 75% of records, 3 times the client has been contacted in the current campaign for a client.\n",
    "   \n",
    "   ** while comparing with 75% quantile,63 is a outlier data point.\n",
    "          \n",
    "  #### Previous:\n",
    "      \n",
    "   ** Average no. of contacts performed before this campaign for a client in the dataset is (approx)0.58 with std of 2.30.\n",
    "   \n",
    "   ** Min. balance is 0\n",
    "   \n",
    "   ** Max. balance is 275\n",
    "   \n",
    "   ** quantile 75%(percentile),for 75% of records, 0 times the client has been contacted before this campaign.\n",
    "   \n",
    "   ** while comparing with 75% quantile,275 is a outlier data point.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'day'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-3912b8a07d23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2743\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2744\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'day'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as m\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "data = pd.read_csv('D:/textAnalysis/marketing-data.csv',sep=',',header='infer')\n",
    "data = data.drop(['day'],axis=1)\n",
    "\n",
    "def binaryType_(data):\n",
    "    \n",
    "    data.is_success.replace(('yes', 'no'), (1, 0), inplace=True)\n",
    "    data.default.replace(('yes','no'),(1,0),inplace=True)\n",
    "    data.housing.replace(('yes','no'),(1,0),inplace=True)\n",
    "    data.loan.replace(('yes','no'),(1,0),inplace=True)\n",
    "    data.marital.replace(('married','single','divorced'),(1,2,3),inplace=True)\n",
    "    data.contact.replace(('telephone','cellular','unknown'),(1,2,3),inplace=True)\n",
    "    data.month.replace(('jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'),(1,2,3,4,5,6,7,8,9,10,11,12),inplace=True)\n",
    "    data.education.replace(('primary','secondary','tertiary','unknown'),(1,2,3,4),inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = binaryType_(data)\n",
    "\n",
    "# for k in range(len(data.contact.unique())):\n",
    "#     data[\"contact_\"+str(data.contact.unique()[k])] = (data.contact == data.contact.unique()[k]).astype(int)\n",
    "\n",
    "# for l in range(len(data.education.unique())):\n",
    "#     data['education_'+str(data.education.unique()[l])] = (data.education == data.education.unique()[l]).astype(int)\n",
    "\n",
    "# for n in range(len(data.month.unique())):\n",
    "#     data['month_'+str(data.month.unique()[n])] = (data.month == data.month.unique()[n]).astype(int)\n",
    "\n",
    "\n",
    "print(data.day.describe())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data = data.drop(['education'],axis=1)\n",
    "#data = data.drop(['marital'],axis=1)\n",
    "#data = data.drop(['contact'],axis=1)\n",
    "data = data.drop(['poutcome'],axis=1)\n",
    "#data = data.drop(['month'],axis=1)\n",
    "data['duration'] = data['duration']/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4    13045\n",
      " 3    11190\n",
      " 5     7672\n",
      " 2     5195\n",
      "-1     3766\n",
      " 0     3514\n",
      " 6      829\n",
      "Name: balance, dtype: int64\n",
      "1.0    18001\n",
      "2.0    10277\n",
      "3.0     6515\n",
      "4.0     5759\n",
      "0.0     4659\n",
      "Name: duration, dtype: int64\n",
      "-1    36954\n",
      " 5     6820\n",
      " 4     1179\n",
      " 3      132\n",
      " 2      126\n",
      "Name: pdays, dtype: int64\n",
      "2    18026\n",
      "1    17544\n",
      "3     9641\n",
      "Name: campaign, dtype: int64\n",
      "2    19274\n",
      "3    11655\n",
      "4    10194\n",
      "1     4088\n",
      "Name: age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def age_(data):\n",
    "    \n",
    "    data.loc[(data['age'] <= 28) & (data['age'] >= 18),'age'] = 1\n",
    "    data.loc[(data['age'] <= 39) & (data['age'] >= 29),'age'] = 2\n",
    "    data.loc[(data['age'] <= 49) & (data['age'] >= 40),'age'] = 3\n",
    "    data.loc[data['age'] >=40,'age'] = 4\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = age_(data)\n",
    "\n",
    "def campaign_(data):\n",
    "    \n",
    "    data.loc[data['campaign'] == 1,'campaign'] = 1\n",
    "    data.loc[(data['campaign'] >= 2) & (data['campaign'] <= 3),'campaign'] = 2\n",
    "    data.loc[data['campaign'] >= 4,'campaign'] = 3\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = campaign_(data)\n",
    "#print(data.campaign.value_counts())\n",
    "def duration_(data):\n",
    "    \n",
    "    data.loc[data['duration'] < 1,'duration'] = 0\n",
    "    data.loc[(data['duration'] >= 1) & (data['duration'] <= 3),'duration'] = 1\n",
    "    data.loc[(data['duration'] > 3) & (data['duration'] <= 5),'duration'] = 2\n",
    "    data.loc[(data['duration'] > 5) & (data['duration'] <= 8),'duration'] = 3\n",
    "    data.loc[data['duration'] > 8,'duration'] = 4\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = duration_(data)\n",
    "\n",
    "def pdays_(data):\n",
    "    \n",
    "    data.loc[~data['pdays'] > 0 ,'pdays'] = 1\n",
    "    data.loc[(data['pdays'] >= 1) & (data['pdays'] <=10) ,'pdays'] = 2\n",
    "    data.loc[(data['pdays'] >= 11) & (data['pdays'] <=50) ,'pdays'] = 3\n",
    "    data.loc[(data['pdays'] >= 51) & (data['pdays'] <=100), 'pdays'] = 4\n",
    "    data.loc[data['pdays'] >= 101,'pdays'] = 5\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = pdays_(data)\n",
    "\n",
    "def balance_(data):\n",
    "    \n",
    "    data.loc[data['balance']<0,'balance'] = -1\n",
    "    data.loc[data['balance'] == 0,'balance'] = 0\n",
    "    data.loc[(data['balance'] >= 1) & (data['balance'] <= 100),'balance'] = 2\n",
    "    data.loc[(data['balance'] >= 101) & (data['balance'] <= 500),'balance'] = 3\n",
    "    data.loc[(data['balance'] >= 501) & (data['balance'] <= 2000),'balance'] = 4\n",
    "    data.loc[(data['balance'] >= 2001) & (data['balance'] <= 10000),'balance'] = 5\n",
    "    data.loc[data['balance'] >= 10001,'balance'] = 6\n",
    "    \n",
    "    return data\n",
    "\n",
    "def job_(data):\n",
    "    \n",
    "    data.loc[data['job'] == \"management\",'job'] = 1\n",
    "    data.loc[data['job'] == \"technician\",'job'] = 2\n",
    "    data.loc[data['job'] == \"entrepreneur\",'job'] = 3\n",
    "    data.loc[data['job'] == \"blue-collar\",'job'] = 4\n",
    "    data.loc[data['job'] == \"retired\",'job'] = 5\n",
    "    data.loc[data['job'] == \"admin.\",'job'] = 6\n",
    "    data.loc[data['job'] == \"services\",'job'] = 7\n",
    "    data.loc[data['job'] == \"self-employed\",'job'] = 8\n",
    "    data.loc[data['job'] == \"unemployed\",'job'] = 9\n",
    "    data.loc[data['job'] == \"student\",'job'] = 10\n",
    "    data.loc[data['job'] == \"housemaid\",'job'] = 11\n",
    "    data.loc[data['job'] == \"unknown\",'job'] = 12\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = balance_(data)\n",
    "data = job_(data)\n",
    "print(data.balance.value_counts())\n",
    "print(data.duration.value_counts())\n",
    "print(data.pdays.value_counts())\n",
    "print(data.campaign.value_counts())\n",
    "print(data.age.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Classifier  Accuracy\n",
      "0  Gradient Boosting Classifier  0.894737\n",
      "0  Gradient Boosting Classifier  0.896064\n",
      "0  Gradient Boosting Classifier  0.896064\n",
      "0  Adaptive Boosting Classifier  0.885670\n",
      "0  Adaptive Boosting Classifier  0.892083\n",
      "0  Adaptive Boosting Classifier  0.882353\n",
      "0  Linear Discriminant Analysis  0.886555\n",
      "0  Linear Discriminant Analysis  0.884122\n",
      "0  Linear Discriminant Analysis  0.887439\n"
     ]
    }
   ],
   "source": [
    "classifiers = {'Gradient Boosting Classifier':GradientBoostingClassifier(),'Adaptive Boosting Classifier':AdaBoostClassifier(),'Linear Discriminant Analysis':LinearDiscriminantAnalysis()}#,'Logistic Regression':LogisticRegression(),'Random Forest Classifier': RandomForestClassifier(),'K Nearest Neighbour':KNeighborsClassifier(8)}#'Decision Tree Classifier':DecisionTreeClassifier(),'Gaussian Naive Bayes Classifier':GaussianNB(),'Support Vector Classifier':SVC(probability=True),}\n",
    "\n",
    "data_y = pd.DataFrame(data['is_success'])\n",
    "#print(data_y.head())\n",
    "data_X = data.drop('is_success',axis=1)\n",
    "#print(data_X.head())\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "metrics_cols = ['Precision Score','Recall Score','F1-Score']\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "metric = pd.DataFrame(columns=metrics_cols)\n",
    "\n",
    "\n",
    "\n",
    "rs = StratifiedShuffleSplit(n_splits=3, test_size=0.1)\n",
    "rs.get_n_splits(data_X,data_y)\n",
    "\n",
    "for Name,classify in classifiers.items():\n",
    "    for train_index, test_index in rs.split(data_X,data_y):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X,X_test = data_X.iloc[train_index], data_X.iloc[test_index]\n",
    "        y,y_test = data_y.iloc[train_index], data_y.iloc[test_index]\n",
    "        cls = classify\n",
    "        cls =cls.fit(X,y)\n",
    "        y_out = cls.predict(X_test)\n",
    "        accuracy = m.accuracy_score(y_test,y_out)\n",
    "        precision = m.precision_score(y_test,y_out,average='macro')\n",
    "        recall = m.recall_score(y_test,y_out,average='macro')\n",
    "        f1_score = m.f1_score(y_test,y_out,average='macro')\n",
    "        log_entry = pd.DataFrame([[Name,accuracy]], columns=log_cols)\n",
    "        metric_entry = pd.DataFrame([[precision,recall,f1_score]], columns=metrics_cols)\n",
    "        log = log.append(log_entry)\n",
    "        metric = metric.append(metric_entry)\n",
    "        \n",
    "        \n",
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    39922\n",
      "1     5289\n",
      "Name: is_success, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.is_success.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Classifier  Accuracy\n",
      "0  Gradient Boosting Classifier  0.892525\n",
      "0  Gradient Boosting Classifier  0.904246\n",
      "0  Gradient Boosting Classifier  0.890093\n",
      "0  Adaptive Boosting Classifier  0.887218\n",
      "0  Adaptive Boosting Classifier  0.891420\n",
      "0  Adaptive Boosting Classifier  0.881026\n",
      "0  Linear Discriminant Analysis  0.877709\n",
      "0  Linear Discriminant Analysis  0.890314\n",
      "0  Linear Discriminant Analysis  0.885670\n"
     ]
    }
   ],
   "source": [
    "classifiers = {'Gradient Boosting Classifier':GradientBoostingClassifier(),'Adaptive Boosting Classifier':AdaBoostClassifier(),'Linear Discriminant Analysis':LinearDiscriminantAnalysis()}#,'Logistic Regression':LogisticRegression(),'Random Forest Classifier': RandomForestClassifier(),'K Nearest Neighbour':KNeighborsClassifier(8)}#'Decision Tree Classifier':DecisionTreeClassifier(),'Gaussian Naive Bayes Classifier':GaussianNB(),'Support Vector Classifier':SVC(probability=True),}\n",
    "\n",
    "data_y = pd.DataFrame(data['is_success'])\n",
    "#print(data_y.head())\n",
    "data_X = data.drop('is_success',axis=1)\n",
    "#print(data_X.head())\n",
    "log_cols = [\"Classifier\", \"Accuracy\"]\n",
    "metrics_cols = ['Precision Score','Recall Score','F1-Score']\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "metric = pd.DataFrame(columns=metrics_cols)\n",
    "\n",
    "\n",
    "\n",
    "rs = ShuffleSplit(n_splits=3, test_size=0.1)\n",
    "rs.get_n_splits(data_X,data_y)\n",
    "\n",
    "for Name,classify in classifiers.items():\n",
    "    for train_index, test_index in rs.split(data_X,data_y):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X,X_test = data_X.iloc[train_index], data_X.iloc[test_index]\n",
    "        y,y_test = data_y.iloc[train_index], data_y.iloc[test_index]\n",
    "        cls = classify\n",
    "        cls =cls.fit(X,y)\n",
    "        y_out = cls.predict(X_test)\n",
    "        accuracy = m.accuracy_score(y_test,y_out)\n",
    "        precision = m.precision_score(y_test,y_out,average='macro')\n",
    "        recall = m.recall_score(y_test,y_out,average='macro')\n",
    "        f1_score = m.f1_score(y_test,y_out,average='macro')\n",
    "        log_entry = pd.DataFrame([[Name,accuracy]], columns=log_cols)\n",
    "        metric_entry = pd.DataFrame([[precision,recall,f1_score]], columns=metrics_cols)\n",
    "        log = log.append(log_entry)\n",
    "        metric = metric.append(metric_entry)\n",
    "        \n",
    "        \n",
    "print(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Precision Score  Recall Score  F1-Score\n",
      "0         0.732960      0.615689  0.646702\n",
      "0         0.774016      0.633289  0.671209\n",
      "0         0.748888      0.605009  0.636500\n",
      "0         0.723847      0.626714  0.655748\n",
      "0         0.747636      0.645415  0.677469\n",
      "0         0.701854      0.615207  0.640819\n",
      "0         0.725005      0.601285  0.628776\n",
      "0         0.694696      0.619192  0.643747\n",
      "0         0.708079      0.609014  0.636041\n"
     ]
    }
   ],
   "source": [
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Classifier  Accuracy\n",
      "0  Gradient Boosting Classifier  0.892525\n",
      "0  Gradient Boosting Classifier  0.904246\n",
      "0  Gradient Boosting Classifier  0.890093\n",
      "0  Adaptive Boosting Classifier  0.887218\n",
      "0  Adaptive Boosting Classifier  0.891420\n",
      "0  Adaptive Boosting Classifier  0.881026\n",
      "0  Linear Discriminant Analysis  0.877709\n",
      "0  Linear Discriminant Analysis  0.890314\n",
      "0  Linear Discriminant Analysis  0.885670\n",
      "0  Gradient Boosting Classifier  0.895621\n",
      "0  Adaptive Boosting Classifier  0.888545\n",
      "0  Linear Discriminant Analysis  0.890977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(data_X,data_y,test_size=0.1)\n",
    "for Name,classify in classifiers.items():\n",
    "#     for train_index, test_index in rs.split(data_X,data_y):\n",
    "#         #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#         X,X_test = data_X.iloc[train_index], data_X.iloc[test_index]\n",
    "#         y,y_test = data_y.iloc[train_index], data_y.iloc[test_index]\n",
    "    cls = classify\n",
    "    cls =cls.fit(X_train,y_train)\n",
    "    y_out = cls.predict(X_test)\n",
    "    accuracy = m.accuracy_score(y_test,y_out)\n",
    "    precision = m.precision_score(y_test,y_out,average='macro')\n",
    "    recall = m.recall_score(y_test,y_out,average='macro')\n",
    "    f1_score = m.f1_score(y_test,y_out,average='macro')\n",
    "    log_entry = pd.DataFrame([[Name,accuracy]], columns=log_cols)\n",
    "    metric_entry = pd.DataFrame([[precision,recall,f1_score]], columns=metrics_cols)\n",
    "    log = log.append(log_entry)\n",
    "    metric = metric.append(metric_entry)\n",
    "\n",
    "        \n",
    "print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
